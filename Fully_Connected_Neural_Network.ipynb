{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2_900170269.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "R9O1NjxYjv8a",
        "GpQ-X57CjbmR",
        "DPx_j-qDjgpw",
        "GO6TiVmbjkhk"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cy5p0juzjq5e"
      },
      "source": [
        "# **Store On Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj-dXMumKaRs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b21e5c00-5b12-4039-82a6-0eaf4fec6f16"
      },
      "source": [
        "# Google Drive Mounting\n",
        "#from google.colab import driveimport tensorflow as tf\n",
        "import tensorflow as tf\n",
        "import os\n",
        "#drive.mount(\"/content/drive\")\n",
        "#datadir = 'drive/My Drive/Practical Deep Machine Learning/HW/flower_photos'\n",
        "numberOfTestPerClass = 100 \n",
        "pixels = 32\n",
        "#!ls 'drive/My Drive/Practical Deep Machine Learning/HW/flower_photos'\n",
        "\n",
        "_URL = \"http://download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "\n",
        "zip_file = tf.keras.utils.get_file(origin=_URL,\n",
        "                                   fname=\"flower_photos.tgz\",\n",
        "                                   extract=True)\n",
        "\n",
        "datadir = os.path.join(os.path.dirname(zip_file), 'flower_photos')\n",
        "print(datadir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "daisy  dandelion  roses  sunflowers  tulips\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9O1NjxYjv8a"
      },
      "source": [
        "# **Store Locally**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go9OtlXW_a4n"
      },
      "source": [
        "#datadir = '/home/ramyelgendi/Downloads/flower_photos'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3ACpuiCjOn3"
      },
      "source": [
        "# **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4NSI5VPqMCk"
      },
      "source": [
        "import os\n",
        "def NavigateDirectory(Directory,numberOfTestPerClass):\n",
        "  Folders = []\n",
        "  ImageNamesTrain = []\n",
        "  ImageNamesVal = []\n",
        "  ImageNamesTest = []\n",
        "\n",
        "  for file in os.listdir(Directory):    # Get Folders\n",
        "    if(os.path.isdir(Directory+'/'+file)):\n",
        "      Folders.append(file)\n",
        "\n",
        "  for folder in Folders:                # Get Images\n",
        "    temp=[]\n",
        "    sortedtemp=[]\n",
        "    for filename in os.listdir(Directory+'/'+folder):\n",
        "      if filename.endswith(\"jpg\"): temp.append(filename)\n",
        "    \n",
        "    sortedtemp = sorted(temp);\n",
        "    ImageNamesTrain.append(sortedtemp[:-numberOfTestPerClass*2])\n",
        "    ImageNamesVal.append(sortedtemp[-numberOfTestPerClass*2:-numberOfTestPerClass])\n",
        "    ImageNamesTest.append(sortedtemp[-numberOfTestPerClass:])\n",
        "\n",
        "\n",
        "\n",
        "  return Folders,ImageNamesTrain,ImageNamesVal,ImageNamesTest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7bFMW0eeBmc",
        "outputId": "b746b770-5d1b-4e0a-a26f-895b760330e9"
      },
      "source": [
        "# Get Class names from Folders & image files (jpg)\n",
        "Folders, ImageNamesTrain, ImageNamesVal, ImageNamesTest = NavigateDirectory(datadir,numberOfTestPerClass)\n",
        "Folders = list(enumerate(Folders))\n",
        "print(Folders)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 'roses'), (1, 'daisy'), (2, 'dandelion'), (3, 'sunflowers'), (4, 'tulips')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndQBRgVQeGpd"
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "\n",
        "def Load(Directory,Folders, ImageNames):\n",
        "  Images = []\n",
        "  ImagesLabels = []\n",
        "  \n",
        "  for folder,listOfImages in zip(Folders,ImageNames):\n",
        "    for name in listOfImages:\n",
        "      image = cv2.imread(Directory+'/'+folder[1]+'/'+name)\n",
        "      image = cv2.resize(image, (pixels,pixels),cv2.INTER_AREA) \n",
        "      Images.append(image)     \n",
        "      ImagesLabels.append(folder[0]) # Number not name\n",
        "\n",
        "\n",
        "  X = np.array(Images)\n",
        "  Y = np.array(ImagesLabels)\n",
        "\n",
        "  return X,Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "AIYiTMZHeHck",
        "outputId": "f1c4ffa6-ec03-410c-a8ab-1353ba99ae66"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Images Loading\n",
        "try:\n",
        "   del TrainData, TrainLabels\n",
        "   del TestData, TestLabels\n",
        "   print('Clear previously loaded data.')\n",
        "except:\n",
        "   pass\n",
        "\n",
        "TrainData,TrainLabels = Load(datadir,Folders,ImageNamesTrain)\n",
        "ValData,ValLabels = Load(datadir,Folders,ImageNamesVal)\n",
        "TestData,TestLabels = Load(datadir,Folders,ImageNamesTest)\n",
        "\n",
        "TrainData = np.array(TrainData).astype(np.float32)\n",
        "ValData = np.array(ValData).astype(np.float32)\n",
        "TestData = np.array(TestData).astype(np.float32)\n",
        "\n",
        "# Normalize the data: subtract the mean image\n",
        "mean_image = np.mean(TrainData, axis=0)\n",
        "TrainData -= mean_image\n",
        "ValData -= mean_image\n",
        "TestData -= mean_image\n",
        "\n",
        "# Transpose so that channels come first\n",
        "TrainData = TrainData.transpose(0, 3, 1, 2).copy()\n",
        "ValData = ValData.transpose(0, 3, 1, 2).copy()\n",
        "TestData = TestData.transpose(0, 3, 1, 2).copy()\n",
        "\n",
        "print(\"Training data shape: \",TrainData.shape)\n",
        "print(\"Training labels shape: \",TrainLabels.shape)\n",
        "print(\"Val data shape: \",ValData.shape)\n",
        "print(\"Val labels shape: \",ValLabels.shape)\n",
        "print(\"Test data shape: \",TestData.shape)\n",
        "print(\"Test labels shape: \",TestLabels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in true_divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-06cf1f4fe45a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Transpose so that channels come first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mTrainData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mValData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mValData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mTestData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTestData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: axes don't match array"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpQ-X57CjbmR"
      },
      "source": [
        "# **Gradient & Activation Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lzlc0sKAj83R"
      },
      "source": [
        "# GRADIENT FUNCTIONS --------------------------------------------------\n",
        "\n",
        "def gradient_forwardprop(x, w, b):\n",
        "    out = None\n",
        "    X = x.reshape(x.shape[0], w.shape[0])\n",
        "    z = np.einsum('ij,kj->ik', X, w.T,optimize=False)\n",
        "    out = z+b\n",
        "    cache = (x, w, b)\n",
        "\n",
        "    return out, cache\n",
        "    \n",
        "def gradient_backwardprop(dout, cache):\n",
        "    x, w, b = cache\n",
        "    dx, dw, db = None, None, None\n",
        "    dim_shape = np.prod(x[0].shape)\n",
        "    N = x.shape[0]\n",
        "    X = x.reshape(N, dim_shape)   # input gradient\n",
        "    dx = np.einsum('ij,kj->ik', dout, w,optimize=False)\n",
        "    dx = dx.reshape(x.shape)      # weight gradient\n",
        "    dw = np.einsum('ij,kj->ik', X.T, dout.T,optimize=False )\n",
        "    db = dout.sum(axis=0)\n",
        "\n",
        "    return dx, dw, db\n",
        "\n",
        "def softmax_loss(x, y):\n",
        "    shifted_logits = x - np.max(x, axis=1, keepdims=True)\n",
        "    Z = np.sum(np.exp(shifted_logits), axis=1, keepdims=True)\n",
        "    log_probs = shifted_logits - np.log(Z)\n",
        "    probs = np.exp(log_probs)\n",
        "    N = x.shape[0]\n",
        "    loss = -np.sum(log_probs[np.arange(N), y]) / N\n",
        "    dx = probs.copy()\n",
        "    dx[np.arange(N), y] -= 1\n",
        "    dx /= N\n",
        "    return loss, dx\n",
        "\n",
        "def forward_relu_fullyconnected(x, w, b, gamma, beta):\n",
        "    bn_cache, do_cache = None, None\n",
        "    \n",
        "    out, fc_cache = gradient_forwardprop(x,w,b)   # Forward Prop\n",
        "    relu_cache = out\n",
        "    out = np.maximum(0,out)\n",
        "    return out, (fc_cache, bn_cache, relu_cache, do_cache)\n",
        "\n",
        "def backward_relu_fullyconnected(dout, cache):\n",
        "    fc_cache, bn_cache, relu_cache, do_cache = cache\n",
        "    dout = dout * (cache > 0)\n",
        "    dgamma, dbeta = None, None      # batch/layer norm\n",
        "    dx, dw, db = gradient_backwardprop(dout, fc_cache)     # Backward Prop\n",
        "    return dx, dw, db, dgamma, dbeta\n",
        "\n",
        "\n",
        "def adam(w, dw, config=None):\n",
        "    if config is None: config = {}\n",
        "    config.setdefault('learning_rate', 1e-3)\n",
        "    config.setdefault('beta1', 0.9)\n",
        "    config.setdefault('beta2', 0.999)\n",
        "    config.setdefault('epsilon', 1e-8)\n",
        "    config.setdefault('m', np.zeros_like(w))\n",
        "    config.setdefault('v', np.zeros_like(w))\n",
        "    config.setdefault('t', 0)\n",
        "\n",
        "    next_w = None\n",
        "    eps, learning_rate = config['epsilon'], config['learning_rate']\n",
        "    beta1, beta2 = config['beta1'], config['beta2']\n",
        "    m, v, t = config['m'], config['v'], config['t']\n",
        "    # Adam\n",
        "    t = t + 1\n",
        "    m = beta1 * m + (1 - beta1) * dw          # momentum\n",
        "    mt = m / (1 - beta1**t)                   # bias correction\n",
        "    v = beta2 * v + (1 - beta2) * (dw * dw)   # RMSprop\n",
        "    vt = v / (1 - beta2**t)                   # bias correction\n",
        "    next_w = w - learning_rate * mt / (np.sqrt(vt) + eps)\n",
        "    # update values\n",
        "    config['m'], config['v'], config['t'] = m, v, t\n",
        "\n",
        "    return next_w, config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPx_j-qDjgpw"
      },
      "source": [
        "# **Fully Connected Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20yPKc6Xj8-B"
      },
      "source": [
        "class FCNN(object):\n",
        "\n",
        "    def __init__(self, data,hidden_dims, input_dim, num_classes, reg, weight_scale,num_epochs,batch_size,learning_rate):\n",
        "\n",
        "        self.reg = reg\n",
        "        self.num_layers = 1 + len(hidden_dims)\n",
        "        self.params = {}\n",
        "        \n",
        "        layers_dims = np.hstack([input_dim, hidden_dims, num_classes])\n",
        "        for i in range(self.num_layers):\n",
        "            self.params['W'+str(i+1)] = weight_scale*np.random.randn(layers_dims[i],layers_dims[i+1])\n",
        "            self.params['b'+str(i+1)] = np.zeros(layers_dims[i+1])\n",
        "\n",
        "        # Cast all parameters to the correct datatype\n",
        "        for k, v in self.params.items():\n",
        "            self.params[k] = v.astype(np.float32)\n",
        "\n",
        "        self.TrainData = data['TrainData']\n",
        "        self.TrainLabels = data['TrainLabels']\n",
        "        self.ValData = data['ValData']\n",
        "        self.ValLabels = data['ValLabels']\n",
        "\n",
        "\n",
        "        # Unpack keyword arguments\n",
        "        self.optim_config = {\"learning_rate\":learning_rate} \n",
        "        self.batch_size = batch_size \n",
        "        self.num_epochs = num_epochs\n",
        "        self.num_train_samples = len(data['TrainData'])\n",
        "        self.num_val_samples = len(data['ValData'])\n",
        "\n",
        "        # Declaration\n",
        "        self.epoch = 0\n",
        "        self.best_val_acc = 0\n",
        "        self.best_params = {}\n",
        "        self.train_loss_history = []\n",
        "        self.val_loss_history = []\n",
        "        self.loss_history = []\n",
        "        self.train_acc_history = []\n",
        "        self.val_acc_history = []\n",
        "\n",
        "        # Make a deep copy of the optim_config for each parameter\n",
        "        self.optim_configs = {}\n",
        "        for p in self.params:\n",
        "            d = {k: v for k, v in self.optim_config.items()}\n",
        "            self.optim_configs[p] = d\n",
        "\n",
        "    def loss(self, X, y=None):\n",
        "        X = X.astype(np.float32)\n",
        "        mode = 'test' if y is None else 'train'\n",
        "\n",
        "        scores = None\n",
        "        x = X\n",
        "        caches = []\n",
        "        gamma, beta = None, None\n",
        "        for i in range(self.num_layers-1):\n",
        "            w = self.params['W'+str(i+1)]\n",
        "            b = self.params['b'+str(i+1)]\n",
        "            x, cache = forward_relu_fullyconnected(x,w,b, gamma, beta )\n",
        "            caches.append(cache)\n",
        "        w = self.params['W'+str(self.num_layers)]\n",
        "        b = self.params['b'+str(self.num_layers)]\n",
        "        scores, cache = gradient_forwardprop(x,w,b)\n",
        "        caches.append(cache)\n",
        "        if mode == 'test':\n",
        "            return scores\n",
        "\n",
        "        loss, grads = 0.0, {}\n",
        "        loss, softmax_grad = softmax_loss(scores, y)\n",
        "        for i in range(self.num_layers):\n",
        "            w = self.params['W'+str(i+1)]\n",
        "            loss += 0.5 * self.reg * np.sum(w * w) \n",
        "\n",
        "        # calculate gradients\n",
        "        dout = softmax_grad\n",
        "        dout, dw, db = gradient_backwardprop(dout, caches[self.num_layers - 1])\n",
        "        grads['W' + str(self.num_layers)] = dw + self.reg * self.params['W' + str(self.num_layers)]\n",
        "        grads['b' + str(self.num_layers)] = db\n",
        "\n",
        "        for i in range(self.num_layers - 2, -1, -1):\n",
        "            dx, dw, db, dgamma, dbeta = backward_relu_fullyconnected(dout, caches[i])\n",
        "\n",
        "            grads['W' + str(i + 1)] = dw + self.reg * self.params['W' + str(i + 1)]\n",
        "            grads['b' + str(i + 1)] = db\n",
        "            dout = dx\n",
        "        return loss, grads\n",
        "\n",
        "    def check_accuracy(self, X, y, num_samples=None, batch_size=100):\n",
        "        # Maybe subsample the data\n",
        "        N = X.shape[0]\n",
        "        if num_samples is not None and N > num_samples:\n",
        "            mask = np.random.choice(N, num_samples)\n",
        "            N = num_samples\n",
        "            X = X[mask]\n",
        "            y = y[mask]\n",
        "\n",
        "        # Compute predictions in batches\n",
        "        num_batches = N // batch_size\n",
        "        if N % batch_size != 0:\n",
        "            num_batches += 1\n",
        "        y_pred = []\n",
        "        for i in range(num_batches):\n",
        "            start = i * batch_size\n",
        "            end = (i + 1) * batch_size\n",
        "            scores = self.loss(X[start:end])\n",
        "            y_pred.append(np.argmax(scores, axis=1))\n",
        "        y_pred = np.hstack(y_pred)\n",
        "        acc = np.mean(y_pred == y)\n",
        "\n",
        "        return acc\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Run optimization to train the model.\n",
        "        \"\"\"\n",
        "        num_train = self.TrainData.shape[0]\n",
        "        iterations_per_epoch = max(num_train // self.batch_size, 1)\n",
        "        num_iterations = self.num_epochs * iterations_per_epoch\n",
        "\n",
        "        for t in range(num_iterations):\n",
        "          # Make a minibatch of training data\n",
        "          num_train = self.TrainData.shape[0]\n",
        "          batch_mask = np.random.choice(num_train, self.batch_size)\n",
        "          X_batch = self.TrainData[batch_mask]\n",
        "          y_batch = self.TrainLabels[batch_mask]\n",
        "\n",
        "          # Compute loss and gradient\n",
        "          loss, grads = self.loss(X_batch, y_batch)\n",
        "          self.loss_history.append(loss)\n",
        "\n",
        "          # Perform a parameter update\n",
        "          for p, w in self.params.items():\n",
        "            dw = grads[p]\n",
        "            next_w, next_config = adam(w, dw, self.optim_configs[p])\n",
        "            self.params[p] = next_w\n",
        "            self.optim_configs[p] = next_config\n",
        "\n",
        "          # At the end of every epoch, increment the epoch counter and decay the learning rate.\n",
        "          epoch_end = (t + 1) % iterations_per_epoch == 0\n",
        "          if epoch_end:\n",
        "              self.epoch += 1\n",
        "\n",
        "          # Check train and val accuracy on the first iteration, the last iteration, and at the end of each epoch.\n",
        "          first_it = (t == 0)\n",
        "          last_it = (t == num_iterations - 1)\n",
        "          if first_it or last_it or epoch_end:\n",
        "              train_acc = self.check_accuracy(self.TrainData, self.TrainLabels,num_samples=self.num_train_samples)\n",
        "              val_acc = self.check_accuracy(self.ValData, self.ValLabels,num_samples=self.num_val_samples)\n",
        "              self.train_acc_history.append(train_acc)\n",
        "              self.val_acc_history.append(val_acc)\n",
        "\n",
        "              train_loss = self.loss(self.TrainData,self.TrainLabels)[0]\n",
        "              val_loss = self.loss(self.ValData,self.ValLabels)[0]\n",
        "              self.train_loss_history.append(train_loss)\n",
        "              self.val_loss_history.append(val_loss)\n",
        "\n",
        "              print('Epoch',self.epoch,'/',self.num_epochs,': Training Loss: ',train_loss,' Validation Loss: ',val_loss,' Training Accuracy: ',train_acc,' Validation Accuracy: ',val_acc)\n",
        "\n",
        "              # Keep track of the best model\n",
        "              if val_acc > self.best_val_acc:\n",
        "                  self.best_val_acc = val_acc\n",
        "                  self.best_params = {}\n",
        "                  for k, v in self.params.items():\n",
        "                      self.best_params[k] = v.copy()\n",
        "\n",
        "        # At the end of training swap the best params into the model\n",
        "        self.params = self.best_params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GO6TiVmbjkhk"
      },
      "source": [
        "# **Main Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raOoUXnfj9M6",
        "outputId": "c7be60be-9345-4a9a-86c7-750596ce5bba"
      },
      "source": [
        "np.random.seed(500)\n",
        "data = {\n",
        "  'TrainData':TrainData,\n",
        "  'TrainLabels': TrainLabels,\n",
        "  'ValData': ValData,\n",
        "  'ValLabels': ValLabels,\n",
        "}\n",
        "\n",
        "# Obtained with random search\n",
        "weight_scale =      2e-2 \n",
        "learning_rate =     10**np.random.uniform(-3, -6)\n",
        "reg =               10**np.random.uniform(-3, -4)\n",
        "hidden_dims =       [100]*3\n",
        "input_dim =         3*pixels*pixels\n",
        "num_classes =       5\n",
        "epochs =            87\n",
        "batch_size=         100\n",
        "\n",
        "model = FCNN(data,hidden_dims,input_dim,num_classes,reg,weight_scale,epochs,batch_size,learning_rate)\n",
        "model.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 / 87 : Training Loss:  1.6900238066262847  Validation Loss:  1.706227888529521  Training Accuracy:  0.171  Validation Accuracy:  0.156\n",
            "Epoch 1 / 87 : Training Loss:  1.6632967016528353  Validation Loss:  1.6867128740947535  Training Accuracy:  0.249  Validation Accuracy:  0.206\n",
            "Epoch 2 / 87 : Training Loss:  1.6385252392954812  Validation Loss:  1.6684927356745192  Training Accuracy:  0.302  Validation Accuracy:  0.234\n",
            "Epoch 3 / 87 : Training Loss:  1.616714340096014  Validation Loss:  1.6519343062272172  Training Accuracy:  0.303  Validation Accuracy:  0.264\n",
            "Epoch 4 / 87 : Training Loss:  1.595508291121015  Validation Loss:  1.6367950795471033  Training Accuracy:  0.349  Validation Accuracy:  0.276\n",
            "Epoch 5 / 87 : Training Loss:  1.5753575409057428  Validation Loss:  1.622575077974885  Training Accuracy:  0.342  Validation Accuracy:  0.288\n",
            "Epoch 6 / 87 : Training Loss:  1.554765422298918  Validation Loss:  1.607769416329817  Training Accuracy:  0.368  Validation Accuracy:  0.298\n",
            "Epoch 7 / 87 : Training Loss:  1.5329550505078018  Validation Loss:  1.5901676215554668  Training Accuracy:  0.39  Validation Accuracy:  0.298\n",
            "Epoch 8 / 87 : Training Loss:  1.5112073772637702  Validation Loss:  1.5732536021364878  Training Accuracy:  0.39  Validation Accuracy:  0.318\n",
            "Epoch 9 / 87 : Training Loss:  1.4890592383001058  Validation Loss:  1.5568384857983502  Training Accuracy:  0.474  Validation Accuracy:  0.318\n",
            "Epoch 10 / 87 : Training Loss:  1.4657411001533198  Validation Loss:  1.5382973773105353  Training Accuracy:  0.457  Validation Accuracy:  0.326\n",
            "Epoch 11 / 87 : Training Loss:  1.442198665838614  Validation Loss:  1.5204171881569073  Training Accuracy:  0.445  Validation Accuracy:  0.328\n",
            "Epoch 12 / 87 : Training Loss:  1.4181257524025146  Validation Loss:  1.5021339068822666  Training Accuracy:  0.451  Validation Accuracy:  0.33\n",
            "Epoch 13 / 87 : Training Loss:  1.3948478991308675  Validation Loss:  1.4784538406175833  Training Accuracy:  0.503  Validation Accuracy:  0.36\n",
            "Epoch 14 / 87 : Training Loss:  1.3712274537267999  Validation Loss:  1.4643587899532453  Training Accuracy:  0.478  Validation Accuracy:  0.36\n",
            "Epoch 15 / 87 : Training Loss:  1.3478242672217466  Validation Loss:  1.448219030725375  Training Accuracy:  0.515  Validation Accuracy:  0.374\n",
            "Epoch 16 / 87 : Training Loss:  1.325966906940341  Validation Loss:  1.4352711335906219  Training Accuracy:  0.463  Validation Accuracy:  0.386\n",
            "Epoch 17 / 87 : Training Loss:  1.305167693787377  Validation Loss:  1.4205522321878628  Training Accuracy:  0.524  Validation Accuracy:  0.396\n",
            "Epoch 18 / 87 : Training Loss:  1.2856482567012053  Validation Loss:  1.4079856476151509  Training Accuracy:  0.523  Validation Accuracy:  0.396\n",
            "Epoch 19 / 87 : Training Loss:  1.2672101443799582  Validation Loss:  1.4001136164802623  Training Accuracy:  0.497  Validation Accuracy:  0.392\n",
            "Epoch 20 / 87 : Training Loss:  1.2499473431734296  Validation Loss:  1.3905217297129602  Training Accuracy:  0.543  Validation Accuracy:  0.408\n",
            "Epoch 21 / 87 : Training Loss:  1.2343387359022056  Validation Loss:  1.3795767972427662  Training Accuracy:  0.541  Validation Accuracy:  0.418\n",
            "Epoch 22 / 87 : Training Loss:  1.219558093243386  Validation Loss:  1.3763448057755725  Training Accuracy:  0.544  Validation Accuracy:  0.42\n",
            "Epoch 23 / 87 : Training Loss:  1.205036269269016  Validation Loss:  1.3712601078179978  Training Accuracy:  0.547  Validation Accuracy:  0.418\n",
            "Epoch 24 / 87 : Training Loss:  1.1909941396467236  Validation Loss:  1.3643413432764637  Training Accuracy:  0.552  Validation Accuracy:  0.428\n",
            "Epoch 25 / 87 : Training Loss:  1.1780991324697372  Validation Loss:  1.3568495165111698  Training Accuracy:  0.579  Validation Accuracy:  0.436\n",
            "Epoch 26 / 87 : Training Loss:  1.1653640189356027  Validation Loss:  1.3545189421638917  Training Accuracy:  0.563  Validation Accuracy:  0.44\n",
            "Epoch 27 / 87 : Training Loss:  1.1530170641991224  Validation Loss:  1.3490733811320579  Training Accuracy:  0.571  Validation Accuracy:  0.444\n",
            "Epoch 28 / 87 : Training Loss:  1.1422651485294257  Validation Loss:  1.342160828246186  Training Accuracy:  0.603  Validation Accuracy:  0.446\n",
            "Epoch 29 / 87 : Training Loss:  1.131570746368342  Validation Loss:  1.3413405894234098  Training Accuracy:  0.558  Validation Accuracy:  0.448\n",
            "Epoch 30 / 87 : Training Loss:  1.1220409141537064  Validation Loss:  1.3476962031357405  Training Accuracy:  0.588  Validation Accuracy:  0.436\n",
            "Epoch 31 / 87 : Training Loss:  1.110615475707209  Validation Loss:  1.346465822076006  Training Accuracy:  0.596  Validation Accuracy:  0.436\n",
            "Epoch 32 / 87 : Training Loss:  1.1007739878192415  Validation Loss:  1.34151039732445  Training Accuracy:  0.593  Validation Accuracy:  0.456\n",
            "Epoch 33 / 87 : Training Loss:  1.0907248476948002  Validation Loss:  1.3416621849343835  Training Accuracy:  0.59  Validation Accuracy:  0.448\n",
            "Epoch 34 / 87 : Training Loss:  1.0810138480595224  Validation Loss:  1.3412801003271955  Training Accuracy:  0.609  Validation Accuracy:  0.466\n",
            "Epoch 35 / 87 : Training Loss:  1.072152051311947  Validation Loss:  1.3331077169289003  Training Accuracy:  0.643  Validation Accuracy:  0.468\n",
            "Epoch 36 / 87 : Training Loss:  1.061910280813426  Validation Loss:  1.331833968123234  Training Accuracy:  0.596  Validation Accuracy:  0.456\n",
            "Epoch 37 / 87 : Training Loss:  1.0522987619373754  Validation Loss:  1.337097875350297  Training Accuracy:  0.597  Validation Accuracy:  0.456\n",
            "Epoch 38 / 87 : Training Loss:  1.0427657855802483  Validation Loss:  1.338411370658227  Training Accuracy:  0.627  Validation Accuracy:  0.47\n",
            "Epoch 39 / 87 : Training Loss:  1.0335910699516602  Validation Loss:  1.33115116832113  Training Accuracy:  0.618  Validation Accuracy:  0.468\n",
            "Epoch 40 / 87 : Training Loss:  1.0243440237408423  Validation Loss:  1.3303242533793314  Training Accuracy:  0.638  Validation Accuracy:  0.47\n",
            "Epoch 41 / 87 : Training Loss:  1.0155498575121074  Validation Loss:  1.3306829918754033  Training Accuracy:  0.651  Validation Accuracy:  0.48\n",
            "Epoch 42 / 87 : Training Loss:  1.006148813928026  Validation Loss:  1.3331378294286695  Training Accuracy:  0.66  Validation Accuracy:  0.478\n",
            "Epoch 43 / 87 : Training Loss:  0.997830641216099  Validation Loss:  1.334487286230144  Training Accuracy:  0.646  Validation Accuracy:  0.464\n",
            "Epoch 44 / 87 : Training Loss:  0.989033302747814  Validation Loss:  1.3468957674525777  Training Accuracy:  0.632  Validation Accuracy:  0.464\n",
            "Epoch 45 / 87 : Training Loss:  0.9793508844701614  Validation Loss:  1.3370080589127527  Training Accuracy:  0.649  Validation Accuracy:  0.464\n",
            "Epoch 46 / 87 : Training Loss:  0.969217163503083  Validation Loss:  1.3370312755627154  Training Accuracy:  0.664  Validation Accuracy:  0.474\n",
            "Epoch 47 / 87 : Training Loss:  0.9601532786445159  Validation Loss:  1.3386716243951888  Training Accuracy:  0.656  Validation Accuracy:  0.474\n",
            "Epoch 48 / 87 : Training Loss:  0.951872063135666  Validation Loss:  1.3368236172233299  Training Accuracy:  0.686  Validation Accuracy:  0.472\n",
            "Epoch 49 / 87 : Training Loss:  0.9423448908255219  Validation Loss:  1.341021368836407  Training Accuracy:  0.689  Validation Accuracy:  0.464\n",
            "Epoch 50 / 87 : Training Loss:  0.9345310983426821  Validation Loss:  1.3308386954137263  Training Accuracy:  0.696  Validation Accuracy:  0.472\n",
            "Epoch 51 / 87 : Training Loss:  0.9244099278808803  Validation Loss:  1.3381320757331743  Training Accuracy:  0.709  Validation Accuracy:  0.474\n",
            "Epoch 52 / 87 : Training Loss:  0.914877551671168  Validation Loss:  1.3419850466969168  Training Accuracy:  0.73  Validation Accuracy:  0.464\n",
            "Epoch 53 / 87 : Training Loss:  0.9058576588139019  Validation Loss:  1.3459882886784271  Training Accuracy:  0.696  Validation Accuracy:  0.474\n",
            "Epoch 54 / 87 : Training Loss:  0.8972321308603413  Validation Loss:  1.346967320576809  Training Accuracy:  0.686  Validation Accuracy:  0.47\n",
            "Epoch 55 / 87 : Training Loss:  0.8878811317195624  Validation Loss:  1.3469433633477514  Training Accuracy:  0.725  Validation Accuracy:  0.474\n",
            "Epoch 56 / 87 : Training Loss:  0.8800618763387003  Validation Loss:  1.3484591681150933  Training Accuracy:  0.716  Validation Accuracy:  0.464\n",
            "Epoch 57 / 87 : Training Loss:  0.8703151550899911  Validation Loss:  1.3446348814696143  Training Accuracy:  0.704  Validation Accuracy:  0.468\n",
            "Epoch 58 / 87 : Training Loss:  0.8606487050780781  Validation Loss:  1.3569328966525747  Training Accuracy:  0.736  Validation Accuracy:  0.456\n",
            "Epoch 59 / 87 : Training Loss:  0.8515282927824555  Validation Loss:  1.3553628061288099  Training Accuracy:  0.713  Validation Accuracy:  0.454\n",
            "Epoch 60 / 87 : Training Loss:  0.8415298265357058  Validation Loss:  1.3545818988964269  Training Accuracy:  0.773  Validation Accuracy:  0.462\n",
            "Epoch 61 / 87 : Training Loss:  0.8325392349044771  Validation Loss:  1.3598413154946576  Training Accuracy:  0.731  Validation Accuracy:  0.464\n",
            "Epoch 62 / 87 : Training Loss:  0.8242028374171314  Validation Loss:  1.3498495997649778  Training Accuracy:  0.756  Validation Accuracy:  0.468\n",
            "Epoch 63 / 87 : Training Loss:  0.8161077847225426  Validation Loss:  1.3696525392652041  Training Accuracy:  0.737  Validation Accuracy:  0.464\n",
            "Epoch 64 / 87 : Training Loss:  0.8049171427994795  Validation Loss:  1.3671978944600014  Training Accuracy:  0.74  Validation Accuracy:  0.46\n",
            "Epoch 65 / 87 : Training Loss:  0.7959879015645103  Validation Loss:  1.366107999549939  Training Accuracy:  0.745  Validation Accuracy:  0.462\n",
            "Epoch 66 / 87 : Training Loss:  0.78638115688727  Validation Loss:  1.3688366428276961  Training Accuracy:  0.747  Validation Accuracy:  0.464\n",
            "Epoch 67 / 87 : Training Loss:  0.778248015739448  Validation Loss:  1.3742899987831045  Training Accuracy:  0.743  Validation Accuracy:  0.466\n",
            "Epoch 68 / 87 : Training Loss:  0.7696716682940441  Validation Loss:  1.3687139622283842  Training Accuracy:  0.788  Validation Accuracy:  0.474\n",
            "Epoch 69 / 87 : Training Loss:  0.7603953148722731  Validation Loss:  1.3780837438867866  Training Accuracy:  0.747  Validation Accuracy:  0.452\n",
            "Epoch 70 / 87 : Training Loss:  0.7509930241290913  Validation Loss:  1.3731971348354348  Training Accuracy:  0.781  Validation Accuracy:  0.47\n",
            "Epoch 71 / 87 : Training Loss:  0.741915990727625  Validation Loss:  1.3881647233908974  Training Accuracy:  0.797  Validation Accuracy:  0.474\n",
            "Epoch 72 / 87 : Training Loss:  0.7330386489574351  Validation Loss:  1.3884887020831669  Training Accuracy:  0.779  Validation Accuracy:  0.474\n",
            "Epoch 73 / 87 : Training Loss:  0.7240612872397141  Validation Loss:  1.3939061084409956  Training Accuracy:  0.782  Validation Accuracy:  0.466\n",
            "Epoch 74 / 87 : Training Loss:  0.7150323883503852  Validation Loss:  1.3943793656699952  Training Accuracy:  0.812  Validation Accuracy:  0.464\n",
            "Epoch 75 / 87 : Training Loss:  0.7071409880798412  Validation Loss:  1.392469875219208  Training Accuracy:  0.779  Validation Accuracy:  0.472\n",
            "Epoch 76 / 87 : Training Loss:  0.6974526711371587  Validation Loss:  1.3964843362676596  Training Accuracy:  0.799  Validation Accuracy:  0.484\n",
            "Epoch 77 / 87 : Training Loss:  0.6891952068094579  Validation Loss:  1.3955842096915974  Training Accuracy:  0.813  Validation Accuracy:  0.468\n",
            "Epoch 78 / 87 : Training Loss:  0.6799041059873107  Validation Loss:  1.3997337488653538  Training Accuracy:  0.796  Validation Accuracy:  0.468\n",
            "Epoch 79 / 87 : Training Loss:  0.6716162948826817  Validation Loss:  1.406752425226344  Training Accuracy:  0.808  Validation Accuracy:  0.472\n",
            "Epoch 80 / 87 : Training Loss:  0.6623682066770306  Validation Loss:  1.4120241009815135  Training Accuracy:  0.841  Validation Accuracy:  0.47\n",
            "Epoch 81 / 87 : Training Loss:  0.6534509706327836  Validation Loss:  1.4183116134267033  Training Accuracy:  0.822  Validation Accuracy:  0.472\n",
            "Epoch 82 / 87 : Training Loss:  0.6459823005960954  Validation Loss:  1.416545901972061  Training Accuracy:  0.809  Validation Accuracy:  0.484\n",
            "Epoch 83 / 87 : Training Loss:  0.6373848525139176  Validation Loss:  1.428856789600616  Training Accuracy:  0.846  Validation Accuracy:  0.472\n",
            "Epoch 84 / 87 : Training Loss:  0.6277814024024064  Validation Loss:  1.4232041789853886  Training Accuracy:  0.842  Validation Accuracy:  0.472\n",
            "Epoch 85 / 87 : Training Loss:  0.6195052930648844  Validation Loss:  1.4256233656889483  Training Accuracy:  0.843  Validation Accuracy:  0.476\n",
            "Epoch 86 / 87 : Training Loss:  0.6105428780192151  Validation Loss:  1.433868144196503  Training Accuracy:  0.841  Validation Accuracy:  0.472\n",
            "Epoch 87 / 87 : Training Loss:  0.601821441867677  Validation Loss:  1.437946671378152  Training Accuracy:  0.839  Validation Accuracy:  0.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12XeaHzdVvKD",
        "outputId": "ad262d63-4b92-4939-eef3-38e164b9dd3e"
      },
      "source": [
        "print(\"weight scale: \",weight_scale,\" learning rate: \",learning_rate,\" reg: \",reg)\n",
        "print('Validation set accuracy: ', ( np.argmax(model.loss(TrainData), axis=1) ==TrainLabels).mean())\n",
        "print('\\n')\n",
        "for i,name in enumerate(Folders):\n",
        "  print('CCR',name[1].upper(),': ', (np.argmax(model.loss(TestData[numberOfTestPerClass*i:numberOfTestPerClass*i+numberOfTestPerClass]), axis=1) == TestLabels[numberOfTestPerClass*i:numberOfTestPerClass*i+numberOfTestPerClass]).mean())\n",
        "print('ACCR: ', (np.argmax(model.loss(TestData), axis=1) == TestLabels).mean())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight scale:  0.02  learning rate:  8.297770501072957e-06  reg:  0.0008675270144593566\n",
            "Validation set accuracy:  0.802247191011236\n",
            "\n",
            "\n",
            "CCR DAISY :  0.4\n",
            "CCR DANDELION :  0.67\n",
            "CCR SUNFLOWERS :  0.62\n",
            "CCR TULIPS :  0.53\n",
            "CCR ROSES :  0.39\n",
            "ACCR:  0.522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "eFPzuoFL_et9",
        "outputId": "d5a59663-6174-4fd0-8e95-e684f947bbd9"
      },
      "source": [
        "plt.plot( range(epochs),model.train_loss_history[0:epochs], 'ro-',  range(epochs),model.val_loss_history[0:epochs], 'bo-')\n",
        "plt.grid()\n",
        "plt.title(\"Loss Graph\")\n",
        "plt.ylabel('Red: Training Loss, Blue: Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Vqyid-O2_w3d",
        "outputId": "7aef4ade-9d4e-46d5-b98d-f8a4bf340c51"
      },
      "source": [
        "plt.plot( range(epochs),model.train_acc_history[0:epochs], 'ro-',  range(epochs),model.val_acc_history[0:epochs], 'bo-')\n",
        "plt.grid()\n",
        "plt.title(\"Accuracy Graph\")\n",
        "plt.ylabel('Red: Training Accuracy, Blue: Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA+8UlEQVR4nO2deZhcVZn/P980IUmTBEhComTpsAoB2cISEGSVAQRRASE0EdEY2RSQAdE4v4HRnnF0ZmSGdTDDImnNiAKCE1kCCYKAEjAgOxGSTlgSEpYkhOzv749zi66urnvrVnVXdVXX+3me81Tde8899dbp6vPe877veY/MDMdxHKd+6dPTAjiO4zg9iysCx3GcOscVgeM4Tp3jisBxHKfOcUXgOI5T57gicBzHqXNcEThOnSFpgaSjeloOp3pwReBULZLmSHpXUr+elqVcSBok6T+iwfkDSW2Sfi1p/56WzakfCioCSb+R9FlJrjSciiFpLHAIYMDnKvzZm1Xoc/oBDwKfBI4HBgO7AjOA43pSNqe+SDO4XwecDrwi6UeSdimzTI4D8GXgceBm4MzsC5JGS7pd0tuSlku6Ouva1yW9IGmlpOcl7ROdN0k7ZtW7WdIPo/eHSVos6TuS3gJukrS1pN9Fn/Fu9H5U1v1DJN0k6Y3o+p3R+WclnZBVr6+kZZL2yvMdJwGjgM+b2bNmttHMPjCzX5vZ5VltmKTzJL0CvBKd+09JiyStkPSkpEOy6l8ezSr+N+qHpyTtmfPZe0l6RtL7Ub3+Kf4mTi+loCIws1lm1gzsAywA7pf0qKSzJPUtt4BO3fJloDUqfydpBICkBuB3wEJgLDCS8ASNpFOAy6N7BxNmEstTft7HgCFAEzCF8L9xU3Q8BvgQuDqr/q1AI7AbMBz4aXT+58AZWfWOA940s3l5PvMo4F4z+yCFfJ8HDgDGRcdPAHtFMv8CuC1nMD8RuC3r+p05/69fAo4BtgP2AL6SQgant2JmBQswFLgAmAvcBZwKXAXMSXO/Fy/FFOBgYD0wLDp+Ebgoen8g8DawWZ777gUuiGnTgB2zjm8Gfhi9PwxYB/RPkGkv4N3o/ceBTcDWeeptC6wEBkfHvwYujWlzFvCjnM94D1gBvJQj+xEF+uxdYM/o/eXA41nX+gBvAodExwuAM7Ku/xi4vqf/7l56rqTxEdwOPEx4+jnBzD5nZv9rZt8EBha633FK4EzgPjNbFh3/gnbz0GhgoZltyHPfaOBvJX7m22a2JnMgqVHSf0taKGkF8Adgq2hGMhp4x8zezW3EzN4A/gicJGkr4FjCrCYfywlKJXPvPDPbCvgikOsgX5R9IOniyAT2vqT3gC2BYfnqm9kmYDFBSWV4K+v9avx/ua5J43i62swezHfBzPbtZnmcOkfSAILZoiGy10MYFLeK7NyLgDGSNsujDBYBO8Q0vZrwMJPhY4TBMUNuGt6LgU8AB5jZW5GN/y+Aos8ZImkrM3svz2fdAkwm/H89Zmavx8j0AHCFpC2ssHnoI/kif8B3gCOB58xsk6R3I9kyjM6q34fgi3ijwGc4dUoaZ/Gu0ZMNAJET7dzyieTUOZ8HNhJs4XtFZVfCrPTLwJ8JZo4fSdpCUn9Jn4runQb8vaTxCuwoqSm6Ng84XVKDpGOAQwvIMYjgF3hP0hDgHzMXzOxN4PfAtdH/Q19Jn866906CT+0Cgs8gjp9H3+UOSbtHsvUHCj1gDQI2EJnIJP0/gk8km/GSvhhFGV0IrCU43x2nE2kUwdezn3qi6fDXyyaRU++cCdxkZm1m9lamEBy1zYSn3hOAHYE2wlP9qQBmdhvQQjAlrSQMyEOidi+I7nsvaufOAnJcCQwAlhEG0Htyrk8i+DFeBJYSBlsiOT4EfkNwxN4e9wGRKepw4Hng/4h8A8B+hFlRHPcSFNHLBKf5GnJMR8BvCf3ybiTrF81sfUKbTh0js+SNaSQ9Q3BCWXTcADxjZrtVQD7HqUmip/SdzeyMgpW7/7MvJzjGK/7ZTm2SxkdwL/ArSdcT7JRn0/npyHGciMiU9DXCk7jjVD1pTEPfIax+PAc4j+DgurScQjlOrSLp6wQzze/N7A89LY/jpKGgachxHMfp3RQ0DUnaCfgXQhTHRysXzWz7MsrlOI7jVIg0PoKbCKFzPyVEOJxFx3jlijJs2DAbO3ZsSfd+8MEHbLHFFt0rUC/B+yYe75t4vG/iqba+efLJJ5eZ2Tb5rqVRBAPM7AFJMrOFwOWSHiYrrrqSjB07lrlz55Z075w5czjssMO6V6BegvdNPN438XjfxFNtfSNpYdy1NIpgTbQy8RVJ5wOvE5JsOY7jOL2ANFFDFxKW5n8LGE/IrHhm0g2O4zhO7ZA4I4gWj33JzC4BVhH8A47jOE4vInFGYGYbCTlLesw57DiO45SXND6CvwC/lXQb8FGGRDOLzaHiOI7j1A5pfARDCHnTjyAk7TqBsL+q4ziOUyqtrTB2LPTpE15b47atKD8FZwRm5n4Bx3Gc7qS1FaZMgdWrw/HChXDWWXDBBfDOOzAkSpr7zjswZgy0tEBzc9nESbND2U2SbswtZZPIcRynlome9A894oj4J/2pU9uVQIb162H5cjALr5n3GSUxbFjZZg9pfAS/y3rfH/gCvtOR4zhOZ7Ke9AVhEJ8yJVzLfqJvayuu3YySSGqzCxScEZjZb7JKK2HDjN275dMdx3F6E/me9FevDuezGTOma5+Tr80ukMZZnMtOQBe/heM4Ti8k7kk/93xLC2y+eXk+qwTS+AhWSlqRKcDdhD0KHMdxnGxGj85/PncG0NwMu+wCDQ0gwdChxSuGrs4qskhjGhpkZoOzys5m9ptuk8BxHKe38MUv5j+/cGFHJ+8778Dzz8PFF8OmTbBsGdx4IzQ1tSuGoUPjlURjY5hVdBNpZgRfkLRl1vFWkj7fbRI4juP0Fl57DQYPhjFj6LTlV8bJ29oKd94JGzbAl77Ufr25GRYsaFcMy5blVxJNTXDDDd0aTprGR/CPZvZ+5sDM3qOHUlA7juNULUuXwv/9H3zjG7BwIWtHjOhcJ+Pk/dWvYLvtYJ990rWdrSQWLOj2NQVpFEG+OmnCTh3HcaqXYlb2pqn7i1+Ep/wzQ3LmfkuX5m+rrQ0eeCDMBqokjVsaRTBX0n9I2kHS9pJ+CjxZbsEcx3HKRibef+HC9kVbGbNNsXUzSuKii4Itf948ANYOj9m2RQoK45ZbejStRDZpFME3gXXA/wK/Aj4EziunUI7jOGUlbbx/obrZSgJg3bqPlMSrkycHp24umzaF17feilc+FSZN1NAHZnaZme0ble+Z2QeF7gOQdIyklyTNl3RZnutbSrpb0tOSnpPkeY0cxyk/aeP9C9VNUBJLjzoqOHUzTt6Ghs5tdPPCsFJJEzV0v6Stso63lnRvivsagGuAY4FxwERJ43KqnQc8b2Z7AocB/y6pi6ssHMepa9LY8+Ni8DPns9uIY8yYwgol28mbmQnE1e1B0piGhkWRQgCY2buk27N4f2C+mb1qZuuAGcCJOXUMGBRtfDMQeAfYkEZwx3GcTqS1/be0wGY5MS8DBoTzuW1Yp0DQQMYclI98iqaQ8ulB0kT/bJI0xszaACQ1QecQ2TyMBBZlHS8GDsipczVwFyGJ3SDgVDPrpDYlTQGmAIwYMYI5c+ak+PjOrFq1quR7ezveN/F438RTbX0z4eKL6Z/HVLPm4ot5fOTIj0712WYbDtpsM9TQQJ+1axHw5iGH8NLIkUw47bTObQCb+vRB0VP9R7E+Zlj2MbCxXz9eOuOMTn0z/Iwz+MS//RsNa9d2qru0p/vQzBILcAzQBtwalYXAMSnuOwWYlnU8Cbgqp87JwE8J/bgj8BowOKnd8ePHW6nMnj275Ht7O9438XjfxFOxvpk+3aypyUwKr9On568nZZ7hOxapY71bbw3nZ80Kx/vsE0qhNpqa8l9raOgkW96+Sfs9ygAw12LG1TQb09wjaR9gQjRgXwS8n3wXEGYA2Yk3RtE5ffVZwI8iIedLeg3YBfhzivYdx6kH8m3iEpeGefhwWLKkcxu55pdrr4Wdd4YjjgjHX/kKfOtb8MwzoW4+s0+STyDJB5BNc3NZN5gplVTZR81sGfB/hD2Lf0QY5AvxBLCTpO0iB/BpBDNQNm3AkQCSRgCfAF5NJ7rjOHVBoVDPbMdu3CKuTK6fc8+FbbeFxx6Dt98Oi8AAJk4M9x98cH4lkMntU8V2/q5QcEYg6QDgdMKGNEMIkT6XFLrPzDZIOh+4F2gAbjSz5ySdHV2/HvgBcLOkvxJmG9+JlI7jOE4gKTInd7YAwQm85ZbtG7lkWLgQrruu/fjdd9tnFhBCPFeu7HhsFsI/s7eKzP28bk4A1xPEKgJJLYRNaNqAXwL/RLAx3ZK2cTObCczMOXd91vs3gKOLlNlxnJ6mtRWmTuXQtrby76mbZKrJN1vYsAEGDgwlKbIHOs4sNm7seC2jBBYsaD+X+Y5TpwZFVIH9hCtBkmloCrAEuA6YbmbLSRct5DhObyYrvFKF0jN0By0t0Ldvx3OZp/Ck2ULa+PykuvnOlzkBXE+QpAg+BrQAnyM4cm8FBkjyhHOOU88Uk56hO2huht12a4/7l4KJp7k52Waf1m6fVLfGbf9piVUEZrbRzH5vZl8mhHb+FngUeF3SLyoloOM4VUYxT8/dwdq18PLLIb3zHXcEk82oUeFaS0vn1A2Z2UJLS/5cP2nr9gLbf1rSRg2tMbNfm9lJhD2LC6aYcBynl1Lpp+fHHgszjqOPhs98Bvr1g7uiAMSTTgoZP7fYovOmLc3NHXP9NDXBOefk3+AlX91u3vylmil683ozW1GMw9hxnF5Gks0eisvzn4b77gtmocMOCwP+EUfA3XeHmcHdd8OHH4aZQj6bfa49/9pr4+37vdD2n5aiFYHjOHVOczN88pPQ0BCiRwYPbn96LibPf1ruvRcOOih8DsDnPgevvgovvADTp4d1AZmFYU5JuCJwHKd43nwTJk7kvb33Diah7LDK7nQkv/02PPVUMAtlOP748HrzzTBzJpx+ev4Uz05qUikCSQdJOl3SlzOl3II5jlOlvP56UAT77cfyCRPg2WfbHcXFOJJzTUjnntvZpDRrVqibrQhGjQo2/J/8JKwZaG2tis1dapk0+xHcCvwbcDCwX1T2LbNcjuNUK088EV733TcoAgibtkN6R3I+E9J113U8PuusUABOPrnj1pBvZKUte/PNqtnpq1ZJsyZgX2BclBjOcZx6Z+7cYIrZay8+XLsWdtghKIJzzgkD9+WXd74nk+vnuOOCOafQil+A9evb37e1taeDmDq14zVoNz/VkYO3O0ljGnqWsLjMcZx6Ii7654knYPfdQ6SQBJ/9LDzwQBiMH388pHYYPbpze9lP/aWQGewrvY6hDki1QxnwvKR7Jd2VKeUWzHGclHR3uGamzbjon7lzYb/92usOGABr1oTQznvuCU/9bW3Bjt/dZPL75KNOVgGXgzSmocvLLYTjOCVSTK7+YoiL/rn0UnjnHdg3uAmHz5oFV13Vsd7ddwe5yvGEnkny1gszgPYkBWcEZvYQ8CJhK8lBwAvROcdxeppiwzXTzh7iBvE33wyv0Yxg+2nTOn/+hx+Gzy/mCT131e/QoWHFcDaZwb7OVwGXgzRRQ18i7Bh2CiEt9Z8knVxuwRzHSUGx4ZppF3vFDeIDB4YUD7vvDkC/uI1g2trS5/qZPr3zqt9ly+DGG+MH+zpeBVwO0vgIpgL7mdmZUQK6/YF/KK9YjuOkohh7edzs4cwzO88QvvGNzvcPGBBW8e6550dP62uHD4///GJy/eTDB/uKkcZH0MfMstX+cnxFsuNUBy0tYSDP3lRlwID89vK42UPm3mz/wltvhRDRj388LCDLbNP+0kthVtDaCs3NvDp5MuN++tN4e32V7tHrdCTNgH5PFDH0FUlfIexdPLPAPY7jlJOMrX/SpDCQDxgQnrIhxPLnG3zT2OxXr4bvfS+Ya046CRYtgltvDUphzZpQZ9Wqj0xKS486yu31vYA0zuJLgBuAPYA9gRvM7DvlFsxxnBhybf0Zfv7zEL//2mv572tpad/cJYlFi0Jk0Ne+Fo6nTu28jWO2Q9pNODVP2v0IfmNm3zazi8zsjnIL5ThOAvls/R9+CN//fhiE77sPlizpfN/pp8OQIdC/f3h6j0vUZhauZRzBvoCr1xOrCCQ9Er2ulLQiq6yUtCJN45KOkfSSpPmSLstz/RJJ86LyrKSNkoaU/nUcpw5IGpgzpqJf/rLz9WefDYP7lVeGp/dbbomP6tm4MTiMW1t9AVcdkLRV5cHR6yAzG5xVBpnZ4EINS2oArgGOBcYBEyWNy/mMn5jZXma2F/Bd4CEze6cL38dxeifZ8f8ZX0AuY8bAuHGh3qWXdo4EuuOOcO+JJ4bj7KiefGTMP3W+jWM9kDb7aMFzedgfmG9mr5rZOmAGcGJC/YlAnscYx6lzcn0CmzZ1rpMZmFtbQ5TP+vWd1wrccQcceCB8LCt1WMa+H6dc2tp8AVcdoEJJRSU9ZWb7ZB1vBjxjZuMSbiNadHaMmU2OjicBB5jZ+XnqNgKLgR3zzQgkTQGmAIwYMWL8jBkzCn6xfKxatYqBAweWdG9vx/smnp7qm+GzZrH9tGn0W7KEfMP0pj59kBlrhw/n1cmTWXrUUUw47TT65/EPrB02jH7LlvG3s89m0amndroed9+aESN4POH/zX838VRb3xx++OFPmln+LQTMLG8hmGpWAhuAFVFZSVhH8C9x92XdfwowLet4EnBVTN1TgbsLtWlmjB8/3kpl9uzZJd/b2/G+iadifTN9ullTk5lkNnSo2eabZ6L38xepcxtS8j3bbhs+J99nNzZ2rNvYmL9uFv67iafa+gaYazHjapKP4F/MbBDwE+voHxhqZt9NoYAWA9m5aEcBb8TUPQ03Czn1TK75Z/lyWLcu+Z58ztpCDtw33sifVsLNP3VNmnUE35W0taT9JX06U1K0/QSwk6TtJG1OGOw7pa+WtCVwKPDbYoV3nF5DvpDQJOKctWny+8QlpfP1AHVLwdUlkiYDFxCe6OcBE4DHgCOS7jOzDZLOB+4FGoAbzew5SWdH16+Pqn4BuM/MPij1SzhOzVNMTH5TU3sWzlyyN5Fva+u44KzUz3N6PWkWlF1A2Kd4oZkdDuwNvJ2mcTObaWY7m9kOZtYSnbs+SwlgZjeb2WklyO44vYc0MfnZmTqTntazn+zjQkN9DYCTRRpFsMbM1gBI6mdmLwKfKK9YjlNn5Ev/0LdvyMvfFZu9rwFwUpBGESyWtBVwJ3C/pN8S7/R1HCeJuI1hTjklDNCZ5HFNTXDTTSEvf1ds9u4EdlJQ0EdgZl+I3l4uaTawJXBPWaVynN5I0raSm20GK1bAzJlw7LHd+7meCtopQFKuoSG5Bfgr8AhQPaskHKcnKGXD+KRtJa+7DrbbDv7u78ohreMkkjQjeBIwQMAY4N3o/VZAG7BduYVznKqk1A3j4yJ1Fi4MZautQrI4f3p3KkzSgrLtzGx7QvjnCWY2zMyGAscDt1dKQMepGjKzgDPOKG7D+AyjRydff++9+D2EHaeMpHEW72dmH+1IZma/JywAc5z6IXvlbxxxT/wZBZImdj+NQnGcbiaNIlgm6fuSxkpqkjSVkG/IcaqTUuz3hUiz8rdPn86fmU+BxGX6zOCLvZwKk2bz+onAPwKZncn+EJ1znOqjVPt9IdIMzvk2gc+nQMzaF3rlm2H4Yi+nwqTJNfSOmV1gZntH5QLzzWOcaiUpMqdYopnFoUccEZ+qAfJv+Zj5zKTdxHyxl1MlJIWPXhm93i3prtxSMQkdpxi6a3/dLJOO4pRAJuVDvo1iMp8Zl49+zBhf7OVUDUmmocwuZP9WCUEcp1sYM6Z7zC1xPoGGhjDwjxnTnvht6tT8n2kGK1cGv0G2ssh+6vfFXk4VkBQ++mT0+lC+UjkRHacIWlqgX7+O55LMLXGO5bgZxKZNnVM+FEr93NDQ9ZxBjlNGYmcEkv5KWFCWFzPboywSOU5XaG6Ga6+Fxx4LT+QNDfEDb5JjedQoWLSo8z35ZhbZqZ/zzQzWrw8momXLSvtOjlNmkkxDx1dMCsfpLlatgnnzwoC+xx5w3nlwwAH56yY5lnffvbMiSJpZZEw8ffrkdyx7SKhTxcQqAjNLWDnjOFXK7beHwXzSJBg2LJx74AHYccfOdQulfNh1V1i9GmtrQ9k+gSS6y0fhOBWkYPiopAmSnpC0StI6SRslraiEcI5TNLfeCttvDwcdBDvvHEw8DzyQv26hwXnBAmhp4aEHH0yfBtpDQp0aJM3K4qsJC8heAQYAk4GryimU4xRNa2sY9GfNChu//+IXwTl75JHw4IP5QzyvuCK5zQ8/LH79gYeEOjVImpXFmNl8SQ1mthG4SdKjZZbLcdKT6/R9//12p++RR8Itt8DTT8Pee3e8L7Mj2PDhsHRp/rZLse17SKhTY6SZEayWtDkwT9KPJV0EbFFmuZzeTHfnAkpy+h55ZDjOZx669lrYaSd4803f29epa5JWFu8bvZ0U1Tsf+AAYDZyUpnFJx0h6SdJ8SZfF1DlM0jxJz0ny9Qm9newkbGbtIZtdUQZJq4m33TY4fXMVwdNPw6OPwjnnBIXktn2njkmaEfxM0ivA14DtzWyFmV1hZt82s/mFGpbUAFwDHAuMAyZKGpdTZyvgWuBzZrYbcEqJ38OpFYrJBZR25rDttvnPZ57mR42Ce+8N7QwbFspee4VrW0STW7ftO3VM0srivQlrCTYCv46e2r8jKWYO3Yn9gflm9qqZrQNmACfm1DkduN3M2qLPjDHUOr2GtLmA8s0czjorDOLZisEMPvaxzu1lnuZbW+EPfwj1zIIjeXlWFvWLLmpXMM3NITqoK5vFO04NIkvKqphdUdoTOA34EvCWmX2qQP2TgWPMbHJ0PAk4wMzOz6pzJdAX2A0YBPynmf08T1tTgCkAI0aMGD9jxoxUMueyatUqBsYlAatzKtU3E049lf55HLNrRozg8RkzGD5rFttPm0a/JUsokLX/o2XvAt4fN45+y5fTb+lS1g4fzquTJ7P0qKOYcNpp9F+yJLGdzGfH4b+beLxv4qm2vjn88MOfNLN98140s4KFMHP4DHAj8BZwZ4p7TgGmZR1PAq7KqXM18DjB+TyMEKK6c1K748ePt1KZPXt2yff2dirWNxdemHk2by+NjWbTp4fS2Nj5epqSaSMXqfC9UqLI/ruJx/smnmrrG2CuxYyriVFDkg6RdC2wGLgEeAT4hJl9PoUCWkxwLGcYBbyRp849ZvaBmS0jbHqzZ4q2nVpl/nzYcssQsgmwzTbttvg0u4DFEednSBP145FBTp2TFDW0CPgR8AKwt5kdbWY3mtn7Kdt+AthJ0nZR+OlpQO4+Br8FDpG0maRG4IDo85xaI41j9403YObMEKmzcCH07w8TJ7bb4ruajyff/YUyg3pkkOMkLig72LqQb8jMNkg6H7gXaABuNLPnJJ0dXb/ezF6QdA/wDLCJYEp6ttTPdHqItNtD3nJLcMR+9atBCRx6KNx3X/v1uDw9ENI4r1wJ69bFy1EoM2hbGwwZEo7feafjngKOU8ckRQ11Oemcmc00s53NbAcza4nOXW9m12fV+YmZjTOz3c3syq5+ptMDFAoJbW0N4Zjf+17YK+DPfw7n/+7v4MUX25/kM8ojm8wuYMuWwY03ti/8yt0AvlBm0Ew00LJloXhkkON8RJqVxY6TTFJIaGa2kKmzdm37ArKjjw7nMrOChQuhb98Q958vlj8zoJuF5HIe8+843UKqXEOOk0icSccMzjwTNm7seD4zW3jttbAY7L774JRTwpP/pEnwP/9T+DM9n4/jdBupZgSSjk86duqcr389/lquEsjQ1hae5o8+OmQMvfnmoCDOOacsIjqOE09a09B+BY6deubZZ4Ptf/TownUzZBy7jY3w7rtw4YWw+ebw0ktlEdFxnHhSKQIz+8ekY6cOyQ4XnTEDjjqq/Sm/ENnpH266qf38unVdT0DnOE7RpNmhrFHSP0j6WXS8k5uG6pzcPEAQNn9pbY1fnNXQ0NmxO3Vq2Pwlm7iFYY7jlI00M4KbgLXAgdHxYuCHZZPIqV4ys4AzzugcLprZzSsunXNmDUF2yGbaBHSO45SVNIpgBzP7MbAewMw+hIL5wJxaIRrcDz3iiM4rgrPNP8OGhYVgcQu+IAzgxaRzjps9eMoHx6koacJH10kaQJTsUdIOhBmCU+tkrQgWtKd6vuCCkKpZajf9ZKdujiMzgKcN7Wxp6bgiGTzlg+P0AGlmBP8I3AOMltQKPABcWlapnMqQb0Xw+vXtg37KFOVAaQO4bwbjOFVBwRmBmd0v6SlgAsEkdEGUKdSpdbrLFt/UVHrOHl8Y5jg9TkFFIOnT0duV0es4SZjZH8onllMRkpK8paGx0Z/gHacXkMY0dElW+QfgbuDyMsrkdAdp0kK3tISFYGnp2zdkAXUzjuP0KgoqAjM7Iat8BtgdSN77z+lZ8u33O2lSGMCzlUJzMxx7LAAmhUF+8807tpVZINbUFBZ/eeZOx+l1lJJ9dDFBGTjVSj4ncMbxm9krIKMMliyBAw7goQcf7JjqOfPUf+ut4V4f+B2n15JmZfFVkv4rKlcDDwNPl180pyBx5p9CTuDM6t333w97A3zmM+3XsnP3++DvOHVBmnUEc7PebwB+aWZ/LJM8TlqSdgVL4wRua4PZs0N20KOOKi5U1HGcXkWa8NFbKiGIUyRJu4K1tMBXvgIbNsTfP2YM3H8/bLEFHHggPPpoWcV1HKd6Sdq8/q+SnslT/irpmUoK6eQhKU9Pc3NICZ2JCMrNCNqvX1AWs2aFfYNzHcSO49QVST6C44ET8pTM+YJIOkbSS5LmS7osz/XDJL0vaV5U/l/xX6EXkxQCmpSnZ+1aWLw4pIrI3daxTx/YeWc45BB4+eWO/gHHceqSxM3rcwvwAdCWZmN7SQ3ANcCxwDhgoqRxeao+bGZ7ReWfSvwevY98IaDZ0T4XX9z5nkyah2efDaki9t03nM92AP/zP8Nf/wq77Rau/fjHnv/fceqcJNPQBElzJN0uaW9JzwLPAkskHZOi7f2B+Wb2qpmtA2YAJ3aP2HVAkg8AwqAOMHBgeB01qn2B19zIv59RBNkMHRpeV60Kr2++CVOmMHzWrO6V33GcmiHJWXw18D1gS+BB4Fgze1zSLsAvCYnokhgJLMo6XgwckKfegZKeBt4A/t7MnsutIGkKMAVgxIgRzJkzp8BH52fVqlUl31tpDm1ry5vr29raeGjOHPb+2c9o2GEHXv72t9nnvPN4bvJk3h45EubMYee772abwYP544IFnaKHJnz/+/TPbXT1asbecANzjjqqTN+mtqml302l8b6Jp6b6xszyFmBe1vsXcq79Je6+rDqnANOyjicBV+XUGQwMjN4fB7xSqN3x48dbqcyePbvkeytOU5NZMAp1LE1NZosWhfc//KHZ2rVmAwaYfetb7ffutZfZ0Ufnb1fK2+4mqRLfqiapqd9NhfG+iafa+gaYazHjapKzeFPW+5z9BEkTdL4YyN7NfBThqT9bCa0ws1XR+5lAX0nDUrTd+2lpgQEDOp7r0yec//Wvw/Epp4SInwkT4JFHwrk1a4KPYPz4/O3GOJnXDh/eTYI7Tu2TJlVXNbXbVZIUwZ6SVkhaCewRvc8cfzJF208AO0naTtLmwGnAXdkVJH1MCrGNkvaP5EmxA0od0NwM554b3kuw9dbBLzBmDNx2G+y5Z4j+gRABNG8erFgBzzwT1g/k8w9A7FaSr06eXLav0luo1n9ip3spFKdRbe12B0lRQw1mNtjMBpnZZtH7zHHfQg2b2QbgfOBe4AXgV2b2nKSzJZ0dVTsZeDbyEfwXcFo0hXEgbPjety988EEIBx08GI48Miz+Wriw/Rd0yCFBSTz2WLKjGGI3g1nq/oFE0ubxc2qfQnEalWi34g8dcTajai016SOYPj3Y9qXwOn16uvsOPDCUTBt9+3a07Tc2hvMrV5o1NJhNnWp21llm22xjtmlTUSJWmz2zmpg9e3asyyb3T1GI3J/COee0Hw8dGkq+n0nSfYXqpr1WCpX63RQjd3bdpD6Nuy/ubxznRouTbfbs2R2uJf1+sv+mmc/Kvt63b/rvEQcJPoIeH9iLLTWnCKZPD6NEsaPG6tXhr3/ppeE4yXlsZrbvvmaf/rTZJz9pduyxRYtZr4og3aC5KfGfOPdPkfRZuT+FNMolzX1JdTODSL4BJq0Ci6MSv5tC/0K5A//mmxevsNP0cb6/b3J/byqoAEotpfzdXBFE9MhgV2gAj2P27FDv7rvDcdwvKvOYctFFZv36mfXpY/YP/1C0mLWuCEp5Csz3T5zp5kIDSjFPjBkKzSrifiZp7yumbr6fYimzhXy/m+6adRR6Qs+0XYxyhTB5zpUtTb8NGtT599XQUHx/d1cpNITk4oogokcGu0IDeBw/+EGot3x5OC6kUC68sP3cNtsU/d9Xy4qg0GAQ9/RUyqCZZoDJVUTZU/5qLsXMFrJnS9nfN58CzbRbjLkrjSLO3Ned3zlfGTIkXb2e+HsVQ7cqAmAW8Hvg+GLv7Y5Sc4qg1BnB0Ueb7b57+3HS/Hj69LCWIO1/cR5qWRGkGQzydXdX/rmrcWAoR0lrDklbksxUpchW7r9DqbOsSrTZozMCYFtgPHBesfd2R6k5RRD3X7PVVvFz5/XrzQYODI9IuW3lm3OXqmyyqAVFEPf10w4GuU/rpQwi+cwoPWkeqEQpxYxS7tK3b5BnzJjyfUbmWao7lU0xfp8kM2XFfQSEbKN9CtWrVKk5RWBmduON7X/BrbeO/3WYhdePfSycHzYs3V+7VPNTFtWuCJImRNtuW77BIM0/X6kDRVLUUNr7Cg0kSaaaYku1zIL69w+KYNSo/NezI2xKseeXoviyzYLdYRorR7RXVxXBdOBvwI+BXQvVL3epSUXw9NOhq2fMSH56LzXCqIZnBGl/4En/jF19Is/cHx+yt6lk2eJKoT9N2j9pmnrFTiSrtWT+FX70o87X4gbb3N9ad0UGJf2LZvtPuiNEt7vosmmIkBPoG8DjwGOEBHCD0tzb3aUmFcFtt4Wufuqp5MequBGtlLjEKvIRxD355Bt8S33qbmjI/xSYZoDJTJyS4sELfb9SwkKLbTPffV350ydFTXWldJcfIC52vivPPdmRSKU5x9NHpVXbLLtbfATAMOBCYEHkLH4F+Gba+7ur1KQi+Od/Dl29cmVpj2FpTDxdnDuWq29KcSzm+4f++MdLu69UR3I2afomaaBImvKnbbPQk26pf/quzhZyo4aSTBqFzCZp+6kbLKFd7rc09CpFQNiN7A7gGeASYHh0vhFYWOj+7i41qQi+8pUwkpl138jYzXRn33TVkZr7D71xo9mOO5amL0sNLc2m2v6hK0FaM0qxfdMdg283WEIrQrX9bpIUQVLSuQynAD81sz3M7CdmtjRKTbEa+GrqXBb1zMsvtyeIy871k4bMrmNVTiY3ihRy8GRy8mzcWHxbffqEMmxYKA0NMH8+HH54crflS6yam1pp6NBQstIs0dxcvIy9ndyfae6216X+LLM3y1uwoLS+j8mbWAv/JtVLnIbIFGA7oH/W8QBgbKH7ylVqckawzTZmX/965/Nxjzb5lj6Wma70TVfiyospSaF3XU2VkES1Pdn1BKX6TyotTzVRbb8bujgjuI2OexNsjM45aXj3XXj7bdhpp87X4h5tbrmla49MFSA7O+KZZ3bOqlgMmafNhobkeplMjTEJVKu1q3oF3fEk35vlqXXSKILNLOw5DED0fvPyidTLeOWV8JoxDWVToyNabkrmNOafhob2r3jOOR2/8q23hnY2bSrcTltbePWBwHG6jzSK4G1Jn8scSDoRWFY+kXoZSYoAqnpEi8uJni+vehK5k5xrr83/lWM2T+tAmjqO4xRHGkVwNvA9SW2SFgHfIawpcNLw8sthJN1++56WJBVxTt+FC+Gss4LzduHCwu1kzD3FTHLyWcqycYeg45SHzQpVMLO/ARMkDQRkZivLL1Yv4uWXw2jYr19PS1KQjMkn87QfYgPaWb8elidsJNrQ0L6bZktL8ZObTP2pU4MJaMiQcPzOO6W36ThOYQoqAgBJnwV2A/pHWwxjZv9URrl6D6+8Em8WqjKKNflk09jYPe6N5mYf7B2n0hQ0DUm6HjgV+CYgwrqClEHwdY5ZmBHkixiqEjKmoCOOODSVyScfNeLjdhwnhjQzgoPMbA9Jz5jZFZL+Hbi93IL1CpYsgZUrq3ZG0NEUpELV89LUFBy+juPULmmcxWui19WStgXWExaZFUTSMZJekjRf0mUJ9faTtFHSyWnarRkKRQz1MGlMQRmn79ChsHlO0LA7bx2nd5BGEdwtaSvgJ8BThKRzvyx0k6QG4BrgWGAcMFHSuJh6/wrcm1rqWuHll8NrD5iGskM/M6kacsNAMzH5+ciN8V+2DG68seaWPDiOk4JE05CkPsADZvYe8BtJvyOkm3g/Rdv7A/PN7NWorRnAicDzOfW+CfwG2K9I2aufl1+Gvn3T5xXqJnKjf7IjfTJhoBdc0DkqKEOcuccduY7TO0lUBGa2KfIJHBgdrwXWpmx7JLAo63gxcEB2BUkjgS8AR5CgCCRNIeyBwIgRI5gzZ05KETqyatWqku8txPBZs9h+2jT6LV3K2uHDWTZhAh+/5x76rF/P2pEjeXXyZJYedVRZPjuXiy+ewOrV/WOvJ4WB9uu3kTPOeIk5c5aWSbrao5y/m1rH+yaemuqbuCREmQJcAZxEWEOQOjkcIbpoWtbxJOCqnDq3AROi9zcDJxdqtyqTzqXJulbOrGjWMQlXaUndqms3pWqi2pKHVRPeN/FUW9+QkHQuTdTQt4EtgA2S1hDCS8zMBhe4bzEwOut4FPBGTp19gRnR2oRhwHGSNpjZnSnkqh7SeF2zM6Z1M7mmoFKQPPrHceqVNCuLB5XY9hPATpK2A14HTgNOz2n7o+gjSTcDv6s5JQDJXtdS6hVJVxaCZRg+fC0Qb05yHKf3kmZB2afzlUL3mdkG4HxCNNALwK/M7DlJZ0s6u+uiVxFpM6F1c8a0TGRQ0kKw3M1Y4sJAJ09+tVtlcxyndkhjGrok631/QjTQkwQHbyJmNhOYmXPu+pi6X0khS3Vy3nlw6aXJdbo56D6NOSgu+qe1tT2fTyaHz8iRSwlRvo7j1BsFZwRmdkJW+QywO7Ck/KLVAJlH8owSGDIkPul+NwfdFzIHJemdKs587ThOD5Aq6VwOiwnKoL7J90i+Zk1YgVWBkTXJ3dDU5Jk6HcdJT0FFIOkqILP0qA+wF/B0GWWqDfI9kndzZFCuCee442DmzHAs5V8Q5rl/HMcpljQzgrlZ7zcAvzSzP5ZJntoh7pG8myKDciccCxfCdde1X8+nBDz3j+M4pZBGEfwaWGNmGyHkBpLUaGZdDFiscUaPzj/od1NkUNqQ0K5uBuM4jpMm6dwDwICs4wHArPKIU0Ocemrnc934SJ52YrFpkzt9HcfpGmkUQX8zW5U5iN4n7Czby4jbwf3xx2HrrcOjeBkig3poaYLjOHVIGtPQB5L2MbOnACSNBz4sr1hVQj5D/ZQp8NJL8PDDcOWVIY1nGWhpga99DdYmpPhzn4DjON1BmhnBhcBtkh6W9DDwv4QVw72fuMigH/wgzBAGlZp9ozDNzbDvvmGyUaGlCY7j1Clpcg09IWkX4BOEhHMvmtn6sktWDSQZ6jdtgm9+E/r1K8tovGwZzJ0L554LV1/d7c07juN8RJpcQ+cBW5jZs2b2V2CgpHPLL1oVUMgAn1k3UAZuuimYhc45pyzNO47jfEQa09DXLexQBoCZvQt8vWwSVRNXXFG4TjdnFG1tDWafSy8Nk41587q1ecdxnE6kUQR9pMwW5h/tMbx5Qv3ew9ix4XWbbeLrlBC2E7ef8LBh8NWvtuuWtWuDbzoTqOQ4jlMO0iiCe4FfSTpS0hGEjevvKa9YVcKsWWHF1iuvwPTpIUwnmxLCdjKBSAsXhtXBy5eHknm/bl3H+mW0PjmO4wDpwke/Q9gv+ByCs/g+4GflFKpquP9+2H9/2HLLdodwbv7mIh3FpWwiU6b9bBzHcYB0aag3mdn1ZnaymZ0EPAdcVX7Reph334UnnoDPfKb9XBH5m+PMP0mbyMThi8YcxyknqdJQS9oLmAicCrwG3F5GmaqD2bPDgJ+tCFKSuw5t+fLSxfBFY47jlJtYRSBpZ8I+wxOB5YSFZDKzwyskW89y//0wcCAccEDRt3ZlD+G+fWHwYHjnHU8k5zhOZUiaEbwIPAycYGbzASRdVBGpqoFZs+Cww8LIXCRpbfpS2NQMfOB3HKfnSPIRnAS8BcyW9DNJRxKcxb2L3KRy554Lo0bB/Pnwxz+WFLuZGdyTaGoKlqdly0LxDKKO4/QUsYrAzO4ws1OBXYA5wEXACEnXSTo6TeOSjpH0kqT5ki7Lc/1ESc9ImidprqSDS/wepZEby5nZ/eX118P1d99NDOSPcwgvXx6e9uNwu7/jONVEmqihD8ys1cyOB0YB84BOg3ou0cKza4BjgXHAREnjcqo9AOxpZnsBXwWmFSV9V0ljzI8J5E9aDwBh+cHQoUEhDB3a/t6TxTmOU20UtXm9mb0D/HdUCrE/MN/MXgWQNAM4EXg+q71VWfW3oH1v5MqQ1pifp14hHbJhQ/A1L1tWomyO4zgVoihFUCQjgUVZx4uBTiE4kr4A/AswHPhsvoYkTSEsamPEiBHMmTOnJIFWrVrV4d4Jw4fTf8mSgvetGT6cx+fMYdas4Uybtj1Ll/aLnvyTXSZtbcacOQ+VJGulye0bpx3vm3i8b+Kpqb4xs7IU4BRgWtbxJOCqhPqfBmYVanf8+PFWKrNnz+54Yvp0s8ZGs2DRyV8aG82mT09VNbc0NZUsasXp1DfOR3jfxON9E0+19Q0w12LG1TS5hkplMTA663gU8EZcZTP7A7CDpGFllKkjzc3w7//efpyw+0uxawPcIew4Tq1Q0DQkaSWdbffvA3OBiy3yAeThCWAnSdsBrxMWp52e0/aOwN/MzCTtQ8hq2oV1uCWw7bbh9Q9/gEMOia2W5E7w9QCO49QyaXwE/0F4kv8FwSh+GvAx4CXgRuCwfDeZ2QZJ5xOylzYAN5rZc5LOjq5fT1ir8GVJ6wn7IJ8aTWEqxyOPwOabw3775b3c2hocw3FSNTWF+H/HcZxaJY0iOMbMsp28N0h63Mz+SdL3km40s5nAzJxz12e9/1fgX4sRuNv54x/D5sD9+3e6lJszKBc3/ziO0xtI4yPYJOlLkvpE5UtZ1yr79N7drFkTNgb+1KfyXk7yC/h6AMdxegtpFEEzIeJnKbAken+GpAHA+WWUrfzMnRt2gjm4fUFz9mrhuJTRkqeDcByn91DQNBQ5g0+IufxI94pTYR6JxD/oIKCwKSiD7w/gOE5vIk3U0DaEzerHZtc3s6+WT6wK8cgjsMsuIUkQ6TJOuF/AcZzeRhpn8W8J6ahnARvLK04F2bQJHn0UTjrpo1OFQkQ9LNRxnN5IGkXQaGbfKbsklaS1FS65JGQXveOOsO9AczNjxuT3C3iIqOM4vZk0zuLfSTqu7JJUiowj4M03w/Hy5R+lmm5p6Zw+2k1BjuP0dtIoggsIyuBDSSskrZS0otyClY18joAo1fTYsWHh2JAhnjLacZz6IU3U0KBKCFIx4hwBbW1cd13YL7itDbbYorJiOY7j9BRJm9fvYmYvRjmAOmFmT5VPrDIS4wh4e+Re3HYbfOMbrgQcx6kvkmYE3ybsAfDvea4ZcERZJCo3LS0weXJYVQy0MpGp+hELF4dEqaNG9aRwjuM4lSdWEZjZlOj18MqJUwGam8OK4iuvpJXTmaKfsdoaP7p8xRUwcqT7BRzHqR9S7VAm6SA6Lyj7eZlkKj/DhwMwdfStrF7U0V+e2aLYFYHjOPVCmpXFtwI7EDatzywoM6B2FcELL8DIkbQtzh80lXYrY8dxnN5AmhnBvsC4iu8TUE5efBF23ZUxm+VfQOa5hBzHqSfSrCN4lrARTe/ALCiCXXahpQUaGjpe9gVkjuPUG2lmBMOA5yX9GVibOWlmnyubVOXk9ddh5UrYdVeOPDKcGjgQPvjAcwk5jlOfpFEEl5dbiIry4ovhdZdduO462LgRnnwSdt65Z8VyHMfpKdKsLH6oEoJUjBdeoJWJfHfSp1n0BgwYAE884YrAcZz6JdZHIOmR6HVllGNoRbG5hiQdI+klSfMlXZbnerOkZ6LyqKQ9S/8q6Wi9ayBTmMaiN4IO/PDDj3LOOY7j1CWxisDMDo5eB5nZ4KwyyMwGF2pYUgNwDXAsMA6YKGlcTrXXgEPNbA/gB8ANpX6RtEx9+FhW09jhXGbtgOM4Tj2SakEZgKThQP/MsZkVirbfH5gfbXWJpBnAicDzWW08mlX/caDsCR7a1g7Pf97XDjiOU6ekWVD2OUK+oW0JG9g3AS8AuxW4dSSwKOt4MXBAQv2vAb+PkWEKIe8RI0aMYM6cOYXEzsuaJUsYQxsLGdvp2vDha5gz5/GS2u0NrFq1quR+7e1438TjfRNPTfWNmSUW4GlgKPCX6Phw4IYU950CTMs6ngRcFVP3cIJyGVqo3fHjx1upPHnNNTadibZZw0YLCwpCaWw0mz695GZ7BbNnz+5pEaoW75t4vG/iqba+AeZazLiaZkHZejNbDvSR1MfMZgN7pbhvMTA663gU8EZuJUl7ANOAE6PPKRuNbW0080uatt1Av36++YzjOA6k8xG8J2kg8AegVdJSYEOK+54AdpK0HfA6cBpwenYFSWOA24FJZvZyUZKXQOPChazcbGsWvNGXyy6DH/6w3J/oOI5T/aSZEZwIrAYuAu4B/gacUOgmM9sAnA/cSzD7/MrMnpN0tqSzo2r/j2B2ulbSPElzS/gOqWlsa+PRbU9m40Zx6KHl/CTHcZzaIXFGEIWA/tbMjgI2AbcU07iZzQRm5py7Puv9ZGByMW12hca2Nh7a4mI22wwOOqhSn+o4jlPdJM4IzGwjsFrSlhWSpzy0tkJTEwMWL+ah+duy33Zv+3aUjuM4EUl7Fk8ws8eBNcBfJd0PfJC5bmbfqoB8Xae1NSwdXr2a1TTy543j+fvX/hNaP+4eYsdxHJJNQ9cC+wD/F5XaZOrUsHQYeIwD2UBfDt0wC6a+6IrAcRyHdEnnivILVB1ZS4Yf4lAa2MCn+CO0fZBwk+M4Tv2QpAi2l3RX3EWrlf0IxoyhdeFBTOWfWUgTm7OOuziB5jGPFr7XcRynDkhSBG8TUkvUNK3HTWfKdXuzmuAdXkc/pvAzOO4vuGHIcRwnWRGstF6wF8HUmQezOufcarZg6syDXRE4juOQHD66oFJClJO4rKKebdRxHCeQtB/BFyspSLkYM6a4847jOPVGmhQTNU1LCzR23IeGxsZw3nEcx6kDRdDcHLKLNjWBZJ5t1HEcJ4derwggDPoLFsCDDz7EggWuBBzHcbJJpQgkPZV07DiO49QuqRSBme2TdOw4juPULnVhGnIcx3HiSco+uhKwuOtmNrgsEjmO4zgVJVYRmNkgAEn/BLwF3AoIaAYGVUQ6x3Ecp+wobG6fUEH6k5kdUOhcpZD0NrCwxNuHAcu6UZzehPdNPN438XjfxFNtfdNkZtvku5Bm8/qNkpqBGQRT0URgYzcKVxRxXyQNkuaa2b7dKU9vwfsmHu+beLxv4qmlvknjLD4d+BKwJCqnROccx3GcXkCajWkWACeWXxTHcRynJyg4I5C0s6QHJD0bHe8h6fvlF60s3NDTAlQx3jfxeN/E430TT830TRpn8UPAJcB/m9ne0blnzWz3CsjnOI7jlJk0PoJGM/tzzrkN5RDGcRzHqTxpFMEySTsQLS6TdDLwZlmlchzHcSpGGkVwHvDfwC6SXgcuBM4up1DlQNIxkl6SNF/SZT0tT08iabSk2ZJekPScpAui80Mk3S/pleh1656WtSeQ1CDpL5J+Fx17vwCStpL0a0kvRr+dA71vApIuiv6XnpX0S0n9a6lvCioCM3vVzI4CtgF2AQ4DDi6zXN2KpAbgGuBYYBwwUdK4npWqR9kAXGxmuwITgPOi/rgMeMDMdgIeiI7rkQuAF7KOvV8C/wncY2a7AHsS+qju+0bSSOBbwL6R77QBOI0a6ptYRSBpsKTvSrpa0meA1cCZwHzCuoJaYn9gfqTU1hEWx9VtSKyZvWlmT0XvVxL+oUcS+uSWqNotwOd7RMAeRNIo4LPAtKzT3i/SYODTwP8AmNk6M3sP75sMmwEDJG0GNAJvUEN9kzQjuBX4BPBX4OvAfYTFZJ83s1obREcCi7KOF0fn6h5JY4G9gT8BI8zsTQjKAhjeg6L1FFcClwKbss55v8D2wNvATZHZbJqkLfC+wcxeB/4NaCP4T983s/uoob5JWlC2vZl9EkDSNELOjDHRE2StoTznkuNm6wBJA4HfABea2QopXzfVD5KOB5aa2ZOSDuthcaqNzYB9gG+a2Z8k/SdVbOqoJJHt/0RgO+A94DZJZ/SoUEWSNCNYn3ljZhuB12pUCUCYAYzOOh5FmLrVLZL6EpRAq5ndHp1eIunj0fWPA0t7Sr4e4lPA5yQtIJgPj5A0He8XCP9Di83sT9HxrwmKwfsGjiKMj2+b2XrgduAgaqhvkhTBnpJWRGUlsEfmvaQVlRKwm3gC2EnSdpI2Jzhy7uphmXoMhUf//wFeMLP/yLp0F8EPRPT620rL1pOY2XfNbJSZjSX8Rh40szOo834BMLO3gEWSPhGdOhJ4Hu8bCCahCZIao/+tIwl+t5rpm4Iri3sLko4j2H8bgBvNrKVnJeo5JB0MPEzw/2Rs4d8j+Al+BYwh/LhPMbN3ekTIHiYyDf29mR0vaSjeL0jai+BE3xx4FTiL8DDpfSNdAZxKiMj7CzAZGEiN9E3dKALHcRwnP75nseM4Tp3jisBxHKfOcUXgOI5T57gicBzHqXNcETiO49Q5rggcJ0LSRknzskq3rZyVNDazy5/jVBsF9yx2nDriQzPbq6eFcJxK4zMCxymApAWS/lXSn6OyY3S+KdrP+5nodUx0foSkOyQ9HZWDoqYaJP0sylt/n6QBUf1vSXo+amdGD31Np45xReA47QzIMQ2dmnVthZntD1xNWKFO9P7nZrYH0Ar8V3T+v4CHzGxPQj6e56LzOwHXmNluhORkJ0XnLwP2jtqpuU2fnNrHVxY7ToSkVWY2MM/5BcARZvZqlKzvLTMbKmkZ8HEzWx+df9PMhkl6GxhlZmuz2hgL3B9tUoKk7wB9zeyHku4BVgF3Anea2aoyf1XH6YDPCBwnHRbzPq5OPtZmvd9Iu4/us4Qd9MYDT0abmzhOxXBF4DjpODXr9bHo/aOELKUAzcAj0fsHgHPgo/2PB8c1KqkPMNrMZhM2xNmKkKzMcSqGP3k4TjsDJM3LOr7HzDIhpP0k/Ynw8DQxOvct4EZJlxB27zorOn8BcIOkrxGe/M8h7FyVjwZguqQtCRso/TTaAtJxKob7CBynAJGPYF8zW9bTsjhOOXDTkOM4Tp3jMwLHcZw6x2cEjuM4dY4rAsdxnDrHFYHjOE6d44rAcRynznFF4DiOU+f8f6nOnU32NQJ/AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}